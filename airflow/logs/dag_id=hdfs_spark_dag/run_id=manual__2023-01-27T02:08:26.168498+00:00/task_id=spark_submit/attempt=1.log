[2023-01-27T03:08:33.577+0100] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: hdfs_spark_dag.spark_submit manual__2023-01-27T02:08:26.168498+00:00 [queued]>
[2023-01-27T03:08:33.586+0100] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: hdfs_spark_dag.spark_submit manual__2023-01-27T02:08:26.168498+00:00 [queued]>
[2023-01-27T03:08:33.587+0100] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2023-01-27T03:08:33.587+0100] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2023-01-27T03:08:33.587+0100] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2023-01-27T03:08:33.608+0100] {taskinstance.py:1300} INFO - Executing <Task(BashOperator): spark_submit> on 2023-01-27 02:08:26.168498+00:00
[2023-01-27T03:08:33.611+0100] {standard_task_runner.py:55} INFO - Started process 11290 to run task
[2023-01-27T03:08:33.613+0100] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'hdfs_spark_dag', 'spark_submit', 'manual__2023-01-27T02:08:26.168498+00:00', '--job-id', '165', '--raw', '--subdir', 'DAGS_FOLDER/hdfs_spark_dag.py', '--cfg-path', '/tmp/tmpojlhv0mg']
[2023-01-27T03:08:33.615+0100] {standard_task_runner.py:83} INFO - Job 165: Subtask spark_submit
[2023-01-27T03:08:33.683+0100] {task_command.py:388} INFO - Running <TaskInstance: hdfs_spark_dag.spark_submit manual__2023-01-27T02:08:26.168498+00:00 [running]> on host LAPTOP-J6R38EUB.localdomain
[2023-01-27T03:08:33.748+0100] {taskinstance.py:1507} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=hdfs_spark_dag
AIRFLOW_CTX_TASK_ID=spark_submit
AIRFLOW_CTX_EXECUTION_DATE=2023-01-27T02:08:26.168498+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-01-27T02:08:26.168498+00:00
[2023-01-27T03:08:33.750+0100] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2023-01-27T03:08:33.751+0100] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\n        sudo docker exec -it spark-spark-1 spark-submit /opt/bitnami/spark/volume/scripts/person_transformations.py\n    ']
[2023-01-27T03:08:33.758+0100] {subprocess.py:86} INFO - Output:
[2023-01-27T03:08:36.936+0100] {subprocess.py:93} INFO - 23/01/27 02:08:36 INFO SparkContext: Running Spark version 3.3.1
[2023-01-27T03:08:37.026+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-01-27T03:08:37.166+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO ResourceUtils: ==============================================================
[2023-01-27T03:08:37.167+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO ResourceUtils: No custom resources configured for spark.driver.
[2023-01-27T03:08:37.168+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO ResourceUtils: ==============================================================
[2023-01-27T03:08:37.169+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO SparkContext: Submitted application: MetadataTransformations
[2023-01-27T03:08:37.220+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2023-01-27T03:08:37.239+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO ResourceProfile: Limiting resource is cpu
[2023-01-27T03:08:37.241+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2023-01-27T03:08:37.310+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO SecurityManager: Changing view acls to: spark
[2023-01-27T03:08:37.311+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO SecurityManager: Changing modify acls to: spark
[2023-01-27T03:08:37.311+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO SecurityManager: Changing view acls groups to:
[2023-01-27T03:08:37.312+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO SecurityManager: Changing modify acls groups to:
[2023-01-27T03:08:37.313+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
[2023-01-27T03:08:37.629+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO Utils: Successfully started service 'sparkDriver' on port 42471.
[2023-01-27T03:08:37.661+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO SparkEnv: Registering MapOutputTracker
[2023-01-27T03:08:37.703+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO SparkEnv: Registering BlockManagerMaster
[2023-01-27T03:08:37.730+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2023-01-27T03:08:37.731+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2023-01-27T03:08:37.736+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2023-01-27T03:08:37.762+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a822c188-6880-4dfd-836d-23bf23c78778
[2023-01-27T03:08:37.822+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
[2023-01-27T03:08:37.843+0100] {subprocess.py:93} INFO - 23/01/27 02:08:37 INFO SparkEnv: Registering OutputCommitCoordinator
[2023-01-27T03:08:38.093+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2023-01-27T03:08:38.218+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO Executor: Starting executor ID driver on host 0633c28c5912
[2023-01-27T03:08:38.232+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2023-01-27T03:08:38.258+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45035.
[2023-01-27T03:08:38.258+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO NettyBlockTransferService: Server created on 0633c28c5912:45035
[2023-01-27T03:08:38.261+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2023-01-27T03:08:38.267+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 0633c28c5912, 45035, None)
[2023-01-27T03:08:38.272+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO BlockManagerMasterEndpoint: Registering block manager 0633c28c5912:45035 with 366.3 MiB RAM, BlockManagerId(driver, 0633c28c5912, 45035, None)
[2023-01-27T03:08:38.275+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 0633c28c5912, 45035, None)
[2023-01-27T03:08:38.277+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 0633c28c5912, 45035, None)
[2023-01-27T03:08:38.911+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2023-01-27T03:08:38.922+0100] {subprocess.py:93} INFO - 23/01/27 02:08:38 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
[2023-01-27T03:08:40.055+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO InMemoryFileIndex: It took 35 ms to list leaf files for 1 paths.
[2023-01-27T03:08:40.289+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 353.7 KiB, free 366.0 MiB)
[2023-01-27T03:08:40.367+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 365.9 MiB)
[2023-01-27T03:08:40.372+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 0633c28c5912:45035 (size: 34.0 KiB, free: 366.3 MiB)
[2023-01-27T03:08:40.377+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
[2023-01-27T03:08:40.902+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO FileInputFormat: Total input files to process : 1
[2023-01-27T03:08:40.906+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO FileInputFormat: Total input files to process : 1
[2023-01-27T03:08:40.923+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
[2023-01-27T03:08:40.941+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2023-01-27T03:08:40.942+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
[2023-01-27T03:08:40.943+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO DAGScheduler: Parents of final stage: List()
[2023-01-27T03:08:40.945+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO DAGScheduler: Missing parents: List()
[2023-01-27T03:08:40.950+0100] {subprocess.py:93} INFO - 23/01/27 02:08:40 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-01-27T03:08:41.020+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.0 KiB, free 365.9 MiB)
[2023-01-27T03:08:41.025+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 365.9 MiB)
[2023-01-27T03:08:41.027+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 0633c28c5912:45035 (size: 4.8 KiB, free: 366.3 MiB)
[2023-01-27T03:08:41.028+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
[2023-01-27T03:08:41.044+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2023-01-27T03:08:41.045+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2023-01-27T03:08:41.106+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (0633c28c5912, executor driver, partition 0, PROCESS_LOCAL, 4595 bytes) taskResourceAssignments Map()
[2023-01-27T03:08:41.123+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2023-01-27T03:08:41.441+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO BinaryFileRDD: Input split: Paths:/opt/bitnami/spark/volume/input/metadata.json:0+1958
[2023-01-27T03:08:41.557+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2519 bytes result sent to driver
[2023-01-27T03:08:41.566+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 475 ms on 0633c28c5912 (executor driver) (1/1)
[2023-01-27T03:08:41.568+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2023-01-27T03:08:41.588+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) finished in 0.607 s
[2023-01-27T03:08:41.598+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-27T03:08:41.598+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2023-01-27T03:08:41.601+0100] {subprocess.py:93} INFO - 23/01/27 02:08:41 INFO DAGScheduler: Job 0 finished: json at NativeMethodAccessorImpl.java:0, took 0.676876 s
[2023-01-27T03:08:43.066+0100] {subprocess.py:93} INFO - 23/01/27 02:08:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 0633c28c5912:45035 in memory (size: 4.8 KiB, free: 366.3 MiB)
[2023-01-27T03:08:43.073+0100] {subprocess.py:93} INFO - 23/01/27 02:08:43 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 0633c28c5912:45035 in memory (size: 34.0 KiB, free: 366.3 MiB)
[2023-01-27T03:08:44.378+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO FileSourceStrategy: Pushed Filters:
[2023-01-27T03:08:44.380+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO FileSourceStrategy: Post-Scan Filters:
[2023-01-27T03:08:44.384+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO FileSourceStrategy: Output Data Schema: struct<dataflows: array<struct<name:string,sinks:array<struct<format:string,input:string,name:string,paths:array<string>,saveMode:string>>,sources:array<struct<format:string,name:string,path:string>>,transformations:array<struct<name:string,params:struct<addFields:array<struct<function:string,name:string>>,input:string,validations:array<struct<field:string,validations:array<string>>>>,type:string>>>>>
[2023-01-27T03:08:44.781+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO CodeGenerator: Code generated in 218.8822 ms
[2023-01-27T03:08:44.792+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 349.5 KiB, free 366.0 MiB)
[2023-01-27T03:08:44.805+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 365.9 MiB)
[2023-01-27T03:08:44.807+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 0633c28c5912:45035 (size: 33.9 KiB, free: 366.3 MiB)
[2023-01-27T03:08:44.808+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO SparkContext: Created broadcast 2 from collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:21
[2023-01-27T03:08:44.823+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-27T03:08:44.882+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO SparkContext: Starting job: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:21
[2023-01-27T03:08:44.883+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO DAGScheduler: Got job 1 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:21) with 1 output partitions
[2023-01-27T03:08:44.884+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO DAGScheduler: Final stage: ResultStage 1 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:21)
[2023-01-27T03:08:44.884+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO DAGScheduler: Parents of final stage: List()
[2023-01-27T03:08:44.884+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO DAGScheduler: Missing parents: List()
[2023-01-27T03:08:44.886+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:21), which has no missing parents
[2023-01-27T03:08:44.896+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.6 KiB, free 365.9 MiB)
[2023-01-27T03:08:44.910+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 365.9 MiB)
[2023-01-27T03:08:44.912+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 0633c28c5912:45035 (size: 7.3 KiB, free: 366.3 MiB)
[2023-01-27T03:08:44.913+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
[2023-01-27T03:08:44.914+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:21) (first 15 tasks are for partitions Vector(0))
[2023-01-27T03:08:44.914+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2023-01-27T03:08:44.919+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (0633c28c5912, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2023-01-27T03:08:44.920+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2023-01-27T03:08:44.971+0100] {subprocess.py:93} INFO - 23/01/27 02:08:44 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/volume/input/metadata.json, range: 0-1958, partition values: [empty row]
[2023-01-27T03:08:45.085+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO CodeGenerator: Code generated in 88.0996 ms
[2023-01-27T03:08:45.123+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1557 bytes result sent to driver
[2023-01-27T03:08:45.125+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 209 ms on 0633c28c5912 (executor driver) (1/1)
[2023-01-27T03:08:45.125+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2023-01-27T03:08:45.127+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: ResultStage 1 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:21) finished in 0.235 s
[2023-01-27T03:08:45.127+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-27T03:08:45.128+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2023-01-27T03:08:45.128+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Job 1 finished: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:21, took 0.246114 s
[2023-01-27T03:08:45.210+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Pushed Filters:
[2023-01-27T03:08:45.210+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Post-Scan Filters:
[2023-01-27T03:08:45.211+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Output Data Schema: struct<dataflows: array<struct<name:string,sinks:array<struct<format:string,input:string,name:string,paths:array<string>,saveMode:string>>,sources:array<struct<format:string,name:string,path:string>>,transformations:array<struct<name:string,params:struct<addFields:array<struct<function:string,name:string>>,input:string,validations:array<struct<field:string,validations:array<string>>>>,type:string>>>>>
[2023-01-27T03:08:45.243+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO CodeGenerator: Code generated in 17.6463 ms
[2023-01-27T03:08:45.249+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 349.5 KiB, free 365.6 MiB)
[2023-01-27T03:08:45.260+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 365.5 MiB)
[2023-01-27T03:08:45.262+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 0633c28c5912:45035 (size: 33.9 KiB, free: 366.2 MiB)
[2023-01-27T03:08:45.263+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO SparkContext: Created broadcast 4 from collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:22
[2023-01-27T03:08:45.264+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-27T03:08:45.282+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO SparkContext: Starting job: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:22
[2023-01-27T03:08:45.283+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Got job 2 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:22) with 1 output partitions
[2023-01-27T03:08:45.283+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Final stage: ResultStage 2 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:22)
[2023-01-27T03:08:45.284+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Parents of final stage: List()
[2023-01-27T03:08:45.284+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Missing parents: List()
[2023-01-27T03:08:45.286+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:22), which has no missing parents
[2023-01-27T03:08:45.291+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.6 KiB, free 365.5 MiB)
[2023-01-27T03:08:45.294+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 365.5 MiB)
[2023-01-27T03:08:45.295+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 0633c28c5912:45035 (size: 7.3 KiB, free: 366.2 MiB)
[2023-01-27T03:08:45.296+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
[2023-01-27T03:08:45.297+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:22) (first 15 tasks are for partitions Vector(0))
[2023-01-27T03:08:45.297+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2023-01-27T03:08:45.299+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (0633c28c5912, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2023-01-27T03:08:45.300+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
[2023-01-27T03:08:45.311+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/volume/input/metadata.json, range: 0-1958, partition values: [empty row]
[2023-01-27T03:08:45.330+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1530 bytes result sent to driver
[2023-01-27T03:08:45.332+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 33 ms on 0633c28c5912 (executor driver) (1/1)
[2023-01-27T03:08:45.332+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2023-01-27T03:08:45.334+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: ResultStage 2 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:22) finished in 0.046 s
[2023-01-27T03:08:45.334+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-27T03:08:45.334+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2023-01-27T03:08:45.335+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Job 2 finished: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:22, took 0.052877 s
[2023-01-27T03:08:45.396+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Pushed Filters:
[2023-01-27T03:08:45.397+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Post-Scan Filters:
[2023-01-27T03:08:45.397+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Output Data Schema: struct<dataflows: array<struct<name:string,sinks:array<struct<format:string,input:string,name:string,paths:array<string>,saveMode:string>>,sources:array<struct<format:string,name:string,path:string>>,transformations:array<struct<name:string,params:struct<addFields:array<struct<function:string,name:string>>,input:string,validations:array<struct<field:string,validations:array<string>>>>,type:string>>>>>
[2023-01-27T03:08:45.423+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO CodeGenerator: Code generated in 14.0483 ms
[2023-01-27T03:08:45.431+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 349.5 KiB, free 365.2 MiB)
[2023-01-27T03:08:45.443+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 365.1 MiB)
[2023-01-27T03:08:45.444+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 0633c28c5912:45035 (size: 33.9 KiB, free: 366.2 MiB)
[2023-01-27T03:08:45.445+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO SparkContext: Created broadcast 6 from collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:23
[2023-01-27T03:08:45.446+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-27T03:08:45.463+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO SparkContext: Starting job: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:23
[2023-01-27T03:08:45.464+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Got job 3 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:23) with 1 output partitions
[2023-01-27T03:08:45.464+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Final stage: ResultStage 3 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:23)
[2023-01-27T03:08:45.465+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Parents of final stage: List()
[2023-01-27T03:08:45.465+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Missing parents: List()
[2023-01-27T03:08:45.466+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[14] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:23), which has no missing parents
[2023-01-27T03:08:45.471+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.6 KiB, free 365.1 MiB)
[2023-01-27T03:08:45.473+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 365.1 MiB)
[2023-01-27T03:08:45.474+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 0633c28c5912:45035 (size: 7.3 KiB, free: 366.2 MiB)
[2023-01-27T03:08:45.476+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
[2023-01-27T03:08:45.477+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:23) (first 15 tasks are for partitions Vector(0))
[2023-01-27T03:08:45.477+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2023-01-27T03:08:45.479+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (0633c28c5912, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2023-01-27T03:08:45.480+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
[2023-01-27T03:08:45.490+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/volume/input/metadata.json, range: 0-1958, partition values: [empty row]
[2023-01-27T03:08:45.507+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1506 bytes result sent to driver
[2023-01-27T03:08:45.509+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 31 ms on 0633c28c5912 (executor driver) (1/1)
[2023-01-27T03:08:45.510+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2023-01-27T03:08:45.511+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: ResultStage 3 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:23) finished in 0.043 s
[2023-01-27T03:08:45.511+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-27T03:08:45.511+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2023-01-27T03:08:45.512+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Job 3 finished: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:23, took 0.049607 s
[2023-01-27T03:08:45.528+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
[2023-01-27T03:08:45.540+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
[2023-01-27T03:08:45.734+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Pushed Filters:
[2023-01-27T03:08:45.734+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Post-Scan Filters:
[2023-01-27T03:08:45.735+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
[2023-01-27T03:08:45.746+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 349.5 KiB, free 364.8 MiB)
[2023-01-27T03:08:45.757+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 364.7 MiB)
[2023-01-27T03:08:45.758+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 0633c28c5912:45035 (size: 33.9 KiB, free: 366.1 MiB)
[2023-01-27T03:08:45.759+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO SparkContext: Created broadcast 8 from load at NativeMethodAccessorImpl.java:0
[2023-01-27T03:08:45.760+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-27T03:08:45.801+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0
[2023-01-27T03:08:45.803+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Got job 4 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2023-01-27T03:08:45.803+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Final stage: ResultStage 4 (load at NativeMethodAccessorImpl.java:0)
[2023-01-27T03:08:45.803+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Parents of final stage: List()
[2023-01-27T03:08:45.804+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Missing parents: List()
[2023-01-27T03:08:45.805+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at load at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-01-27T03:08:45.828+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 14.5 KiB, free 364.7 MiB)
[2023-01-27T03:08:45.830+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.7 MiB)
[2023-01-27T03:08:45.831+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 0633c28c5912:45035 (size: 7.0 KiB, free: 366.1 MiB)
[2023-01-27T03:08:45.832+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
[2023-01-27T03:08:45.834+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2023-01-27T03:08:45.834+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2023-01-27T03:08:45.836+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (0633c28c5912, executor driver, partition 0, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2023-01-27T03:08:45.838+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
[2023-01-27T03:08:45.854+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/volume/input/person_inputs.json, range: 0-111, partition values: [empty row]
[2023-01-27T03:08:45.869+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO CodeGenerator: Code generated in 11.5984 ms
[2023-01-27T03:08:45.893+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2003 bytes result sent to driver
[2023-01-27T03:08:45.894+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 60 ms on 0633c28c5912 (executor driver) (1/1)
[2023-01-27T03:08:45.895+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2023-01-27T03:08:45.896+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: ResultStage 4 (load at NativeMethodAccessorImpl.java:0) finished in 0.089 s
[2023-01-27T03:08:45.896+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-27T03:08:45.896+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2023-01-27T03:08:45.897+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO DAGScheduler: Job 4 finished: load at NativeMethodAccessorImpl.java:0, took 0.095302 s
[2023-01-27T03:08:45.935+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Pushed Filters:
[2023-01-27T03:08:45.935+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Post-Scan Filters:
[2023-01-27T03:08:45.937+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceStrategy: Output Data Schema: struct<dataflows: array<struct<name:string,sinks:array<struct<format:string,input:string,name:string,paths:array<string>,saveMode:string>>,sources:array<struct<format:string,name:string,path:string>>,transformations:array<struct<name:string,params:struct<addFields:array<struct<function:string,name:string>>,input:string,validations:array<struct<field:string,validations:array<string>>>>,type:string>>>>>
[2023-01-27T03:08:45.972+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO CodeGenerator: Code generated in 19.2127 ms
[2023-01-27T03:08:45.978+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 349.5 KiB, free 364.4 MiB)
[2023-01-27T03:08:45.989+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 364.3 MiB)
[2023-01-27T03:08:45.991+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 0633c28c5912:45035 (size: 33.9 KiB, free: 366.1 MiB)
[2023-01-27T03:08:45.993+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO SparkContext: Created broadcast 10 from collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:27
[2023-01-27T03:08:45.994+0100] {subprocess.py:93} INFO - 23/01/27 02:08:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-27T03:08:46.010+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Starting job: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:27
[2023-01-27T03:08:46.011+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Got job 5 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:27) with 1 output partitions
[2023-01-27T03:08:46.012+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Final stage: ResultStage 5 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:27)
[2023-01-27T03:08:46.012+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Parents of final stage: List()
[2023-01-27T03:08:46.012+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Missing parents: List()
[2023-01-27T03:08:46.013+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[22] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:27), which has no missing parents
[2023-01-27T03:08:46.017+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 19.4 KiB, free 364.3 MiB)
[2023-01-27T03:08:46.019+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 364.3 MiB)
[2023-01-27T03:08:46.021+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 0633c28c5912:45035 (size: 8.5 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.022+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
[2023-01-27T03:08:46.024+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[22] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:27) (first 15 tasks are for partitions Vector(0))
[2023-01-27T03:08:46.024+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2023-01-27T03:08:46.026+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (0633c28c5912, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2023-01-27T03:08:46.028+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
[2023-01-27T03:08:46.035+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/volume/input/metadata.json, range: 0-1958, partition values: [empty row]
[2023-01-27T03:08:46.051+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1607 bytes result sent to driver
[2023-01-27T03:08:46.052+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 26 ms on 0633c28c5912 (executor driver) (1/1)
[2023-01-27T03:08:46.052+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2023-01-27T03:08:46.054+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: ResultStage 5 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:27) finished in 0.038 s
[2023-01-27T03:08:46.055+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-27T03:08:46.055+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2023-01-27T03:08:46.056+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Job 5 finished: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:27, took 0.044519 s
[2023-01-27T03:08:46.144+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceStrategy: Pushed Filters:
[2023-01-27T03:08:46.144+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceStrategy: Post-Scan Filters:
[2023-01-27T03:08:46.145+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceStrategy: Output Data Schema: struct<dataflows: array<struct<name:string,sinks:array<struct<format:string,input:string,name:string,paths:array<string>,saveMode:string>>,sources:array<struct<format:string,name:string,path:string>>,transformations:array<struct<name:string,params:struct<addFields:array<struct<function:string,name:string>>,input:string,validations:array<struct<field:string,validations:array<string>>>>,type:string>>>>>
[2023-01-27T03:08:46.187+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO CodeGenerator: Code generated in 31.1968 ms
[2023-01-27T03:08:46.194+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 349.5 KiB, free 364.0 MiB)
[2023-01-27T03:08:46.204+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 363.9 MiB)
[2023-01-27T03:08:46.205+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 0633c28c5912:45035 (size: 33.9 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.207+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Created broadcast 12 from collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:44
[2023-01-27T03:08:46.208+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-27T03:08:46.238+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 0633c28c5912:45035 in memory (size: 7.3 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.243+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 0633c28c5912:45035 in memory (size: 33.9 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.248+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 0633c28c5912:45035 in memory (size: 8.5 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.253+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 0633c28c5912:45035 in memory (size: 7.3 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.258+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 0633c28c5912:45035 in memory (size: 7.3 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.260+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Starting job: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:44
[2023-01-27T03:08:46.261+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Got job 6 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:44) with 1 output partitions
[2023-01-27T03:08:46.262+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Final stage: ResultStage 6 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:44)
[2023-01-27T03:08:46.262+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Parents of final stage: List()
[2023-01-27T03:08:46.263+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Missing parents: List()
[2023-01-27T03:08:46.264+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 0633c28c5912:45035 in memory (size: 7.0 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.264+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:44), which has no missing parents
[2023-01-27T03:08:46.269+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 23.5 KiB, free 364.4 MiB)
[2023-01-27T03:08:46.272+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 364.4 MiB)
[2023-01-27T03:08:46.273+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 0633c28c5912:45035 (size: 9.2 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.274+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513
[2023-01-27T03:08:46.275+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:44) (first 15 tasks are for partitions Vector(0))
[2023-01-27T03:08:46.276+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2023-01-27T03:08:46.277+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (0633c28c5912, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2023-01-27T03:08:46.279+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
[2023-01-27T03:08:46.285+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/volume/input/metadata.json, range: 0-1958, partition values: [empty row]
[2023-01-27T03:08:46.300+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1803 bytes result sent to driver
[2023-01-27T03:08:46.302+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 25 ms on 0633c28c5912 (executor driver) (1/1)
[2023-01-27T03:08:46.302+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2023-01-27T03:08:46.304+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: ResultStage 6 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:44) finished in 0.038 s
[2023-01-27T03:08:46.306+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-27T03:08:46.306+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
[2023-01-27T03:08:46.306+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Job 6 finished: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:44, took 0.046183 s
[2023-01-27T03:08:46.372+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceStrategy: Pushed Filters:
[2023-01-27T03:08:46.373+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceStrategy: Post-Scan Filters:
[2023-01-27T03:08:46.374+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceStrategy: Output Data Schema: struct<dataflows: array<struct<name:string,sinks:array<struct<format:string,input:string,name:string,paths:array<string>,saveMode:string>>,sources:array<struct<format:string,name:string,path:string>>,transformations:array<struct<name:string,params:struct<addFields:array<struct<function:string,name:string>>,input:string,validations:array<struct<field:string,validations:array<string>>>>,type:string>>>>>
[2023-01-27T03:08:46.413+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO CodeGenerator: Code generated in 27.5874 ms
[2023-01-27T03:08:46.418+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 349.5 KiB, free 364.1 MiB)
[2023-01-27T03:08:46.431+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 364.0 MiB)
[2023-01-27T03:08:46.432+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 0633c28c5912:45035 (size: 33.9 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.433+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Created broadcast 14 from collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:55
[2023-01-27T03:08:46.434+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-27T03:08:46.467+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Starting job: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:55
[2023-01-27T03:08:46.468+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Got job 7 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:55) with 1 output partitions
[2023-01-27T03:08:46.468+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Final stage: ResultStage 7 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:55)
[2023-01-27T03:08:46.469+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Parents of final stage: List()
[2023-01-27T03:08:46.469+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Missing parents: List()
[2023-01-27T03:08:46.470+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[30] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:55), which has no missing parents
[2023-01-27T03:08:46.473+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 18.8 KiB, free 364.0 MiB)
[2023-01-27T03:08:46.475+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 364.0 MiB)
[2023-01-27T03:08:46.476+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 0633c28c5912:45035 (size: 8.2 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.477+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513
[2023-01-27T03:08:46.478+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[30] at collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:55) (first 15 tasks are for partitions Vector(0))
[2023-01-27T03:08:46.478+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
[2023-01-27T03:08:46.480+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (0633c28c5912, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2023-01-27T03:08:46.481+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
[2023-01-27T03:08:46.489+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/volume/input/metadata.json, range: 0-1958, partition values: [empty row]
[2023-01-27T03:08:46.501+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1730 bytes result sent to driver
[2023-01-27T03:08:46.502+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 22 ms on 0633c28c5912 (executor driver) (1/1)
[2023-01-27T03:08:46.502+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2023-01-27T03:08:46.503+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: ResultStage 7 (collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:55) finished in 0.032 s
[2023-01-27T03:08:46.504+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-27T03:08:46.505+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2023-01-27T03:08:46.505+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Job 7 finished: collect at /opt/bitnami/spark/volume/scripts/person_transformations.py:55, took 0.037856 s
[2023-01-27T03:08:46.613+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(office),Not(EqualTo(office,)),IsNotNull(age)
[2023-01-27T03:08:46.614+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(office#22),NOT (office#22 = ),isnotnull(age#20L)
[2023-01-27T03:08:46.615+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceStrategy: Output Data Schema: struct<age: bigint, name: string, office: string ... 1 more fields>
[2023-01-27T03:08:46.678+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-01-27T03:08:46.678+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-01-27T03:08:46.679+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[2023-01-27T03:08:46.720+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO CodeGenerator: Code generated in 15.0482 ms
[2023-01-27T03:08:46.725+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 349.4 KiB, free 363.7 MiB)
[2023-01-27T03:08:46.739+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 363.6 MiB)
[2023-01-27T03:08:46.740+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 0633c28c5912:45035 (size: 33.8 KiB, free: 366.1 MiB)
[2023-01-27T03:08:46.741+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Created broadcast 16 from save at NativeMethodAccessorImpl.java:0
[2023-01-27T03:08:46.744+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-27T03:08:46.798+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0
[2023-01-27T03:08:46.799+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Got job 8 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2023-01-27T03:08:46.800+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Final stage: ResultStage 8 (save at NativeMethodAccessorImpl.java:0)
[2023-01-27T03:08:46.800+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Parents of final stage: List()
[2023-01-27T03:08:46.800+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Missing parents: List()
[2023-01-27T03:08:46.800+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[33] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-01-27T03:08:46.823+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 212.9 KiB, free 363.4 MiB)
[2023-01-27T03:08:46.825+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 76.2 KiB, free 363.3 MiB)
[2023-01-27T03:08:46.826+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 0633c28c5912:45035 (size: 76.2 KiB, free: 366.0 MiB)
[2023-01-27T03:08:46.827+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513
[2023-01-27T03:08:46.828+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[33] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2023-01-27T03:08:46.828+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2023-01-27T03:08:46.829+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (0633c28c5912, executor driver, partition 0, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2023-01-27T03:08:46.830+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
[2023-01-27T03:08:46.862+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-01-27T03:08:46.862+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-01-27T03:08:46.863+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[2023-01-27T03:08:46.897+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/volume/input/person_inputs.json, range: 0-111, partition values: [empty row]
[2023-01-27T03:08:46.909+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO CodeGenerator: Code generated in 8.9026 ms
[2023-01-27T03:08:46.930+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO CodeGenerator: Code generated in 6.8825 ms
[2023-01-27T03:08:46.939+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO CodeGenerator: Code generated in 6.1582 ms
[2023-01-27T03:08:46.962+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileOutputCommitter: Saved output of task 'attempt_202301270208465811588268217078754_0008_m_000000_8' to file:/opt/bitnami/spark/volume/output/events/ok_with_date/_temporary/0/task_202301270208465811588268217078754_0008_m_000000
[2023-01-27T03:08:46.962+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO SparkHadoopMapRedUtil: attempt_202301270208465811588268217078754_0008_m_000000_8: Committed. Elapsed time: 1 ms.
[2023-01-27T03:08:46.972+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2622 bytes result sent to driver
[2023-01-27T03:08:46.974+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 144 ms on 0633c28c5912 (executor driver) (1/1)
[2023-01-27T03:08:46.974+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2023-01-27T03:08:46.975+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: ResultStage 8 (save at NativeMethodAccessorImpl.java:0) finished in 0.173 s
[2023-01-27T03:08:46.976+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-27T03:08:46.976+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2023-01-27T03:08:46.977+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO DAGScheduler: Job 8 finished: save at NativeMethodAccessorImpl.java:0, took 0.178694 s
[2023-01-27T03:08:46.979+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileFormatWriter: Start to commit write Job 7029fb5f-62fe-4471-b36d-8d1cf5674629.
[2023-01-27T03:08:46.994+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileFormatWriter: Write Job 7029fb5f-62fe-4471-b36d-8d1cf5674629 committed. Elapsed time: 14 ms.
[2023-01-27T03:08:46.999+0100] {subprocess.py:93} INFO - 23/01/27 02:08:46 INFO FileFormatWriter: Finished processing stats for write job 7029fb5f-62fe-4471-b36d-8d1cf5674629.
[2023-01-27T03:08:47.043+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileSourceStrategy: Pushed Filters: Or(Or(IsNull(office),EqualTo(office,)),IsNull(age))
[2023-01-27T03:08:47.044+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileSourceStrategy: Post-Scan Filters: ((isnull(office#22) OR (office#22 = )) OR isnull(age#20L))
[2023-01-27T03:08:47.044+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileSourceStrategy: Output Data Schema: struct<age: bigint, name: string, office: string ... 1 more fields>
[2023-01-27T03:08:47.055+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-01-27T03:08:47.056+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-01-27T03:08:47.056+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[2023-01-27T03:08:47.085+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO CodeGenerator: Code generated in 10.6696 ms
[2023-01-27T03:08:47.089+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 349.4 KiB, free 363.0 MiB)
[2023-01-27T03:08:47.102+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 363.0 MiB)
[2023-01-27T03:08:47.103+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 0633c28c5912:45035 (size: 33.8 KiB, free: 365.9 MiB)
[2023-01-27T03:08:47.104+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO SparkContext: Created broadcast 18 from save at NativeMethodAccessorImpl.java:0
[2023-01-27T03:08:47.105+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-27T03:08:47.130+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0
[2023-01-27T03:08:47.131+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO DAGScheduler: Got job 9 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2023-01-27T03:08:47.131+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO DAGScheduler: Final stage: ResultStage 9 (save at NativeMethodAccessorImpl.java:0)
[2023-01-27T03:08:47.131+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO DAGScheduler: Parents of final stage: List()
[2023-01-27T03:08:47.131+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO DAGScheduler: Missing parents: List()
[2023-01-27T03:08:47.132+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-01-27T03:08:47.154+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 213.1 KiB, free 362.8 MiB)
[2023-01-27T03:08:47.157+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 76.3 KiB, free 362.7 MiB)
[2023-01-27T03:08:47.158+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 0633c28c5912:45035 (size: 76.3 KiB, free: 365.9 MiB)
[2023-01-27T03:08:47.159+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513
[2023-01-27T03:08:47.160+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2023-01-27T03:08:47.160+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2023-01-27T03:08:47.161+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (0633c28c5912, executor driver, partition 0, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2023-01-27T03:08:47.162+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
[2023-01-27T03:08:47.179+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-01-27T03:08:47.179+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-01-27T03:08:47.179+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[2023-01-27T03:08:47.199+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/volume/input/person_inputs.json, range: 0-111, partition values: [empty row]
[2023-01-27T03:08:47.214+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO CodeGenerator: Code generated in 6.8606 ms
[2023-01-27T03:08:47.221+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileOutputCommitter: Saved output of task 'attempt_202301270208474417314119073029300_0009_m_000000_9' to file:/opt/bitnami/spark/volume/output/discards/validation_ko/_temporary/0/task_202301270208474417314119073029300_0009_m_000000
[2023-01-27T03:08:47.221+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO SparkHadoopMapRedUtil: attempt_202301270208474417314119073029300_0009_m_000000_9: Committed. Elapsed time: 1 ms.
[2023-01-27T03:08:47.224+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2579 bytes result sent to driver
[2023-01-27T03:08:47.225+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 63 ms on 0633c28c5912 (executor driver) (1/1)
[2023-01-27T03:08:47.225+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2023-01-27T03:08:47.226+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO DAGScheduler: ResultStage 9 (save at NativeMethodAccessorImpl.java:0) finished in 0.094 s
[2023-01-27T03:08:47.227+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-27T03:08:47.227+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2023-01-27T03:08:47.227+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO DAGScheduler: Job 9 finished: save at NativeMethodAccessorImpl.java:0, took 0.097570 s
[2023-01-27T03:08:47.228+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileFormatWriter: Start to commit write Job db013816-a33f-4099-a459-d8d3299412e3.
[2023-01-27T03:08:47.240+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileFormatWriter: Write Job db013816-a33f-4099-a459-d8d3299412e3 committed. Elapsed time: 11 ms.
[2023-01-27T03:08:47.241+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO FileFormatWriter: Finished processing stats for write job db013816-a33f-4099-a459-d8d3299412e3.
[2023-01-27T03:08:47.256+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO SparkUI: Stopped Spark web UI at http://0633c28c5912:4040
[2023-01-27T03:08:47.272+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2023-01-27T03:08:47.291+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO MemoryStore: MemoryStore cleared
[2023-01-27T03:08:47.292+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO BlockManager: BlockManager stopped
[2023-01-27T03:08:47.297+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO BlockManagerMaster: BlockManagerMaster stopped
[2023-01-27T03:08:47.300+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2023-01-27T03:08:47.307+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO SparkContext: Successfully stopped SparkContext
[2023-01-27T03:08:47.657+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO ShutdownHookManager: Shutdown hook called
[2023-01-27T03:08:47.658+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-f9116a38-adb8-4741-a7e5-184ac0cfb93c
[2023-01-27T03:08:47.662+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-e7241569-c572-4c9e-acd6-b3a0a1ddb66c
[2023-01-27T03:08:47.666+0100] {subprocess.py:93} INFO - 23/01/27 02:08:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-f9116a38-adb8-4741-a7e5-184ac0cfb93c/pyspark-1fcd86c9-a440-4494-9a11-2c907eb7f191
[2023-01-27T03:08:47.704+0100] {subprocess.py:97} INFO - Command exited with return code 0
[2023-01-27T03:08:47.726+0100] {taskinstance.py:1318} INFO - Marking task as SUCCESS. dag_id=hdfs_spark_dag, task_id=spark_submit, execution_date=20230127T020826, start_date=20230127T020833, end_date=20230127T020847
[2023-01-27T03:08:47.784+0100] {local_task_job.py:208} INFO - Task exited with return code 0
[2023-01-27T03:08:47.796+0100] {taskinstance.py:2578} INFO - 1 downstream tasks scheduled from follow-on schedule check
